<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://{{ db_host }}:3306/hive_metastore?createDatabaseIfNotExist=true&amp;useUnicode=true&amp;characterEncoding=UTF-8</value>
</property>
<property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
</property>
<property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>{{ db_username }}</value>
</property>
<property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>{{ db_password }}</value>
</property>
<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
</property>
<property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
</property>
<property>
    <name>hive.metastore.event.db.notification.api.auth</name>
    <value>false</value>
</property>
<property>
    <name>hive.cli.print.header</name>
    <value>true</value>
</property>
<property>
    <name>hive.cli.print.current.db</name>
    <value>true</value>
</property>
<!--Spark依赖位置-->
<property>
    <name>spark.yarn.jars</name>
    <value>hdfs://mycluster/spark-jars/*</value>
</property>
<!--Hive执行引擎-->
<property>
    <name>hive.execution.engine</name>
    <value>spark</value>
</property>
<!--Hive和Spark连接超时时间-->
<property>
    <name>hive.spark.client.connect.timeout</name>
    <value>90000ms</value>
</property>
<property>
  <name>spark.home</name>
  <value>/data/spark</value>
</property>
<property>
  <name>spark.master</name>
  <value>yarn</value>
</property>
<property>
  <name>spark.executor.memory</name>
  <value>1g</value>
</property>
<property>
  <name>spark.driver.memory</name>
  <value>1g</value>
</property>
<property>
  <name>spark.driver.cores</name>
  <value>1</value>
</property>
<property>
  <name>spark.executor.cores</name>
  <value>3</value>
</property>
<property>
  <name>spark.executor.instances</name>
  <value>2</value>
</property>
<property>
  <name>hive.merge.sparkfiles</name>
  <value>true</value>
</property>

<property>
    <name>hive.insert.into.multilevel.dirs</name>
    <value>true</value>
    <description>允许生成多级目录</description>
</property>
<property>
    <name>hive.exec.stagingdir</name>
    <value>/tmp/hive/staging/.hive-staging</value>
    <description>临时文件暂放目录解决datax导出路径文件会包含临时文件问题</description>
</property>

<!-- hiveserver2高可用 -->
<property>
    <name>hive.server2.support.dynamic.service.discovery</name>
    <value>true</value>
</property>
<property>
    <name>hive.server2.zookeeper.namespace</name>
    <value>hiveserver2_zk</value>
</property>
<property>
    <name>hive.zookeeper.quorum</name>
    <value>{% for vhost in groups['zk'] %}{{ vhost }}:2181{% if loop.index != groups['zk']|length %},{% endif %}{% endfor %}</value>
</property>
<property>
    <name>hive.zookeeper.client.port</name>
    <value>2181</value>
</property>
<property>
    <name>hive.server2.thrift.bind.host</name>
    <value>{{ inventory_hostname }}</value>
</property>
<property>
    <name>hive.server2.thrift.port</name>
    <value>10000</value>
</property>


</configuration>
